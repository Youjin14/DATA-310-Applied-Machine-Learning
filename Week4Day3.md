A.Using NLP to build a sarcasm classifier1.Pick two or three news sources and select a few news titles from their feed (about 5 is likely enough).  For example you could select CNN, Fox News, MSNBC, NPR, PBS, Al Jazeera, RT (Russia Today), Deutsche Welle, Facebook, BBC, France24, CCTV, NHK World or another source you wish you analyze.  Run your sarcasm model to predict whether the titles are interpreted as sarcastic or not.  Analyze the results and comment on the different news sources you have selected.B.Text generation with an RNN1.Use the generate_text() command at the end of the exercise to produce synthetic output from your RNN model.  Run it a second time and review the output.  How has your RNN model been able to “learn” and “remember” the shakespeare text in order to reproduce a similar output?2.Stretch goal - replace the Shakespeare text with your own selected text and run the model again.  Modify the source text as needed in order to generate_text() from the newly trained model.C.Neural machine translation with attention1.Use the translate() command at the end of the exercise to translate three sentences from Spanish to English.  How did your translations turn out? 2.Stretch goal - pick a scene from a movie that is acted out in a language other than English.  Download the appropriate language dataset and translate the scene.  How did your translation turn out this time? 
